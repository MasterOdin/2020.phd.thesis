\section{The Cognitive Event Calculus}

To capture the room in a formal way, we employ the
\textbf{cognitive event calculus} (\CEC), a cognitive calculus and
intensional logic.  While the full syntax
and inference schemata are outside the scope of this paper, we give a
brief overview.\footnote{For a more in-depth primer on the \DCEC, see
  the appendix in \cite{nsg_sb_dde_ijcai}.} \DCEC\ is a multi-sorted
quantified modal logic with a well-defined syntax and proof calculus.
\DCEC\ subsumes the event calculus~\cite{mueller_commonsense_2014}, a first-order
calculus used for modeling events and actions and their effects upon
the world.  The proof calculus of \DCEC\ is based on natural deduction
\cite{gentzen_investigations_1964} and includes all the introduction and elimination
rules for first-order logic, as well as inference schemata for the
modal operators and related structures.  \DCEC\ is a sorted system and
includes the built-in sorts shown in Table~\ref{syn:sorts}.

Table~\ref{syn:terms} presents the syntax of our language for forming
terms, while Table~\ref{syn:defs} presents a list of built-in function
symbols, which come from the standard event calculus, in our language.
Table~\ref{syn:formulae} shows the syntax for
formulae in the language, and finally Table~\ref{rules} shows a subset of
inference schemata needed for our current purpose. The main
inference schemata needed include $I_{\knows}$ and $I_{\believes}$,
which state that knowledge and belief are closed under the inference
system of $\DCEC$.  We also have inference schemata that let us go
from perception to knowledge ($I_1$), knowledge to belief ($I_2$),
common knowledge to knowledge ($I_3$), and from knowledge to
propositions that hold ($I_4$). Below, we also use \emph{derived
  inference schemata} for converting perceptions to knowledge,
knowledge to belief, common knowledge to belief,~labeled as
$D_{[\perceives \leadsto \knows]}$, $D_{[\knows \leadsto \believes]}$,
and $D_{[\common \leadsto \believes]}$ respectively
\cite{ArkoudasAndBringsjord2008Pricai}.


\begin{table}
\begin{footnotesize}
\begin{center}

\begin{tabular}{lp{8cm}}
\toprule
\textbf{Sort}    & \textbf{Description} \\
\midrule
\type{Agent} & Human and non-human actors.  \\

\type{Moment} &  Time points. E.g., $t_i$, $birthday(son(jack))$ etc. \\

  \type{Event} & Used for events in the domain. \\
  \type{ActionType} & Abstract actions
                      instantiated by agents.\\
  \type{Action} & Events that occur
                  as actions by agents \\
  \type{Fluent} & Representing states of the world.\\
  \type{Formula} & Represents any arbitrary formula\\
  \bottomrule
\end{tabular}
\caption{Basic sorts in the language}
\label{syn:sorts}
\end{center}
\end{footnotesize}
\end{table}




\begin{table}
\begin{footnotesize}
\begin{center}
  \begin{tabular}{lp{10.3cm}}
    \toprule
    \textbf{Terms} & \textbf{Explanation}  \\
    \midrule
    $x: S$ & A variable $x$ of sort $S$. E.g. ${a_i}:\type{Agent}$ representing
             an agent. \\
    $c: S$ & A constant $c$ of sort $S$. E.g. ${jack}:\type{Agent}$ representing
             an agent named ``jack.'' \\
$ f(t_1,\ldots,t_n)$ & A function expression. E.g. $\action(eating, john) $\\
    \bottomrule
  \end{tabular}
\caption{Syntax for terms in the language}
\label{syn:terms}
\end{center}
\end{footnotesize}
\end{table}

%% Moved the the tables for syntax, formula, and schema into the middle of
%% the reasoner-planner section
%% to force latex to put them onto the same page and save some space // Matt

To handle reasoning within \DCEC\, we utilize a quantified modal logic
theorem prover, \textsf{ShadowProver}, first presented in
\cite{nsg_sb_dde_ijcai,uncertaintyized_cognitive_calculus}.\footnote{The
  prover is available in both Java and Common Lisp and can be obtained
  at: \url{https://github.com/naveensundarg/prover}. The underlying
  first-order prover is SNARK, available at:
  \url{http://www.ai.sri.com/~stickel/snark.html}.}  The prover works
by utilizing a technique called \textbf{shadowing} to achieve speed
without sacrificing consistency in the system.  Shadowing is a
syntactic operation that converts any modal formula (or a set of
formulae) $\phi$ to a non-modal formula $\mathsf{shadow}[\phi]$ by replacing atomic
modal sub-formuale with propositional atoms.

\begin{table}
\begin{footnotesize}
\begin{center}
\begin{tabular}{lp{10.3cm}}
\toprule
\textbf{Function Symbols} $f$& \textbf{Sort}  \\
\midrule
$\action$ & $\Agent \times \ActionType \rightarrow \Action$\\
$ \initially$ & $\Fluent \rightarrow \Boolean$\\
  $\holds$ & $ \Fluent \times \Moment \rightarrow \Boolean $\\
  $ \happens$ & $ \Event \times \Moment \rightarrow \Boolean$ \\
  $ \clipped$ & $ \Moment \times \Fluent \times \Moment \rightarrow \Boolean$ \\
  $ \initiates$ & $ \Event \times \Fluent \times \Moment \rightarrow \Boolean$\\
  $ \terminates$ & $ \Event \times \Fluent \times \Moment \rightarrow \Boolean$ \\
  $ \prior$ & $\Moment \times \Moment \rightarrow \Boolean$\\
\bottomrule
\end{tabular}
\caption{Builtin function symbols in the language}
\label{syn:defs}
\end{center}
\end{footnotesize}
\end{table}


\begin{table}
\begin{footnotesize}
\begin{center}
\begin{tabular}{lp{10.3cm}}
\toprule
\textbf{Formula Expressions} $\phi$& \textbf{Explanation}  \\
\midrule
$A(\ldots)$ & Atomic formulae such as $\holds(raining, t_2)$\\
$\neg \phi$ & Negations. E.g., $\lnot\holds(raining, t_2)$\\
$\phi \lor \psi$ & Disjunctions. E.g., $\holds(cloudy, t_2)
\lor \holds(sunny, t_2)$\\
$\phi \lif \psi$ & Implications. E.g.,  $\holds(cloudy, t_2) \lif
                   \lnot \holds(sunny, t_2)$\\
$\perceives (a,t,\phi)$ & Agent $a$ perceives at time $t$ that $\phi$
                          occurs or holds \\
$\knows (a,t,\phi)$ & Agent $a$ knows at time $t$ that $\phi$
                          occurs or holds \\
$\believes (a,t,\phi)$ & Agent $a$ believes at time $t$ that $\phi$
                          \\
$\intends (a,t,\phi)$ & Agent $a$ intends at time $t$ that $\phi$
                          \\
$\desires (a,t,\phi)$ & Agent $a$ desires at time $t$ that $\phi$
                          \\

$\says (a,b,t,\phi)$ & Agent $a$ communicates to agent $b$ at time $t$
                       that $\phi$ \\
$\common (t,\phi)$ &At time $t$ $\phi$ is common knowledge.
                          \\
\bottomrule
\end{tabular}
\caption{Syntax for formulae in the language}
\label{syn:formulae}
\end{center}
\end{footnotesize}
\end{table}





{ % begin box to localize effect of arraystretch change
\renewcommand{\arraystretch}{2}

\begin{table}
\begin{footnotesize}
\begin{center}
  \begin{tabular}{lp{8cm}}
\toprule
\textbf{Inference Scheme} $\phi$& \textbf{Explanation}  \\
\midrule
$\infer[{[I_{\knows}]}]{\knows(a,t_2,\phi)}{\knows(a,t_1,\Gamma), \
    \ \Gamma\vdash\phi, \ \ t_1 \leq t_2}$ & From prior knowledge, agents
                                             can infer new knowledge
                                             at at later time.\\
$\infer[{[I_{\believes}]}]{\believes(a,t_2,\phi)}{\believes(a,t_1,\Gamma), \
    \ \Gamma\vdash\phi, \ \ t_1 \leq t_2} $ & From prior belief, agents
                                              can infer new beliefs at
                                              a later time.\\
$\infer[{[I_1]}]{\common(t,\perceives(a,t,\phi)
   \lif\knows(a,t,\phi))}{}$ & It is common knowledge that perception
                               leads to knowledge\\
$\infer[{[I_2]}]{\common(t,\knows(a,t,\phi)
    \lif\believes(a,t,\phi))}{}$ & It is common knowledge that
                                   knowledge leads to belief \\
$\infer[{[I_3]}]{\knows(a_1, t_1, \ldots
    \knows(a_n,t_n,\phi)\ldots)}{\common(t,\phi) \ t\leq t_1 \ldots t\leq
    t_n}$ & Definition of common knowledge \\
$\infer[{[I_4]}]{\phi}{\knows(a,t,\phi)}$ & If $\phi$ is known, then
                                            $\phi$ holds\\
\bottomrule
\end{tabular}
\caption{Inference schema}
\label{rules}
\end{center}
\end{footnotesize}
\end{table}
}

The prover can be equipped
with multiple sets of inference schemes $\rho^p_{q}$, where
$q\in\mathbb{N}$ denotes the degree of the schemes (e.g. $0$ for
propositional schemes, $1$ for first-order quantifier schemes, etc.)
and $p\in\{0,1\}$ denotes the modality of the schemes. For example, pure
propositional logic and first-order schemes are given by $\rho^0_{0}$
and $\rho^0_{1}$, while modal
propositional or modal first-order schemas are given by $\rho^1_{0}$ and
$\rho^1_{1}$.


% Given any arbitrary formula $\phi$, $\mathsf{A}_{[\phi]}$ is a unique
% atomic (propositional) symbol. We define the \textsf{level} of a
% formula: $\mathsf{level}(\phi) = 0$ if $\phi$ is purely propositional;
% $\mathsf{level} (\phi) = 1$ if $\phi$ is purely first-order; and
% $\mathsf{level} (\phi) = 2$ if $\phi$ is modal.  Given the above
% definition, we can define the operation of \textbf{shadowing} a
% formula to a level.  To shadow a formula $\chi$ to a level $l$,
% replace all subformulae $\chi'$ in $\chi$ such that
% $\mathsf{level}(\chi')>l$ with $\mathsf{A}_{[\chi']}$
% simultaneously. We denote this by $\mathsf{S}[\phi,l]$.
Starting from a set of modal formula $\Gamma$ as premises and a goal
$\phi$, the prover operates in two phases. In the first phase, it
expands $\Gamma$ using the modal schemes $\rho^1_{0}$ and
$\rho^1_{1}, $ and checks if $\phi$ is contained in the expanded
set. In the second phase, the prover applies the non-modal schemes
$\rho^0_{0} $ and $\rho^0_{1}$ to $\mathsf{shadow}[\Gamma]$ and checks whether
the expanded set contains $\mathsf{shadow}[\phi]$. The two phases are repeated
till either the goal is reached or no expansions happen.

Planning for the room is handled by \textsf{Spectra}, a planner based
on an \emph{extension} of the STRIPS-style
planning language, and backed by \textsf{ShadowProver}. In this planning formalism, arbitrary
formulae of \DCEC\ are allowed in states, actions, and goals.  For
instance, valid states and goals can include: \emph{``No three blocks
on the table should be of the same color.''}  and \emph{``Jack
believes that Jill believes there is one block on the table.''}

\begin{comment}
\subsection{Non-modal Systems are not Enough}
\label{sect:prop_not_enough}
 In an \textbf{extensional} system, two
terms $t_1$ and $t_2$ are considered to be identical if they denote
the same set of objects. Logics such as propositional logic,
first-order logic, higher-order logic, etc. are extensional systems
and are best suited to modeling states of the world. In an
\textbf{intensional} system, the meaning of a term $t$ is dependent on
the context $C$ in which it occurs. Modal logics are intensional
systems. \DCEC\ is an {intensional} logic in the sense that it has
intensional operators.\footnote{Please note that there is a vast difference between
  intension and intention.} Intensional systems are crucial for modeling
theory-of-mind reasoning.

For example, using an extensional system such as first-order logic to
model theory-of-mind reasoning leads to unsound inferences as shown
below, in which we have an agent $r$ that knows the manager of a team
is the most responsible person in the team.  Agent $r$ does not know
that $\mathit{Moe}$ is the manager of the team, but it's true that
$\mathit{Moe}$ is the manager.  If the knowledge operator $\mathbf{K}$
is a simple first-order predicate, we get the proof shown below, which
produces a contradiction (that $r$ knows that $\mathit{Moe}$ is the
manager) from true premises.  This unsoundness persists even with more
robust representation schemes in extensional logics
\cite{selmer_naveen_metaphil_web_intelligence}.

\vspace{10pt}

\begin{minipage}[b]{0.7\textwidth}
\begin{footnotesize}
 \begin{footnotesize}
\begin{equation*}
\begin{aligned}
&\fbox{1}\ \ \mathbf{K}\left(r,\
  \mathsf{Manager}\left(\mathit{team}, \mathit{mostResponsible}\left(\mathit{team}\right) \right)\right) \mbox{
  {\color{gray}; given}} \\
&\fbox{2}\ \ \lnot \mathbf{K}\left(r,\mathsf{Manager}\left(\mathit{team}, \mathit{Moe}\right)\right) \mbox{
  {\color{gray}; given}}\\
&\fbox{3}\ \ \mathit{Moe} = \mathit{mostResponsible}\left(\mathit{team}\right)  \mbox{
  {\color{gray}; given}}\\
&\fbox{4}\ \ \mathbf{K}\left(r,\mathsf{Manager}\left(\mathit{team}, \mathit{Moe}\right)\right)  \mbox{
  {\color{gray}; first-order inference from \fbox{3} and \fbox{1}}}\\
& \fbox{5}\ \ \mathbf{\bot}  \mbox{
  {\color{gray}; first-order inference from \fbox{4} and \fbox{2}}}
\end{aligned}
\end{equation*}
\end{footnotesize}
\end{footnotesize}
\end{minipage}
\end{comment}
